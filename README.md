# Graph Attention Networks (GAT) Implementation in PyTorch

This project is an implementation of **Graph Attention Networks (GAT)** based on the original paper by Veličković et al. (2018), using PyTorch and PyTorch Geometric.

## Key Features

- **Graph Attention Network Model:** Implements GAT with multi-head self-attention.
- **Supported Datasets:** Includes standard citation datasets like **Cora**, **CiteSeer**, and **PubMed**.
<!-- - **Modular Design:** Easy to extend and modify for other datasets or variations of GAT. -->
<!-- - **Training & Evaluation Scripts:** Full training and evaluation pipelines with hyperparameter tuning. -->

## Project Structure

- **`models/`**: Contains the GAT model and layer definitions.
- **`data/`**: Scripts for loading and preprocessing datasets.
- **`scripts/`**: High-level scripts for training, evaluation, and visualization.
- **`experiments/`**: Configuration files for different experiments.
